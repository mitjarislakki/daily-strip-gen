{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel #pip install transformers --user\n",
    "import torch #pip install torch --user\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from framesToStrip import display_images_with_same_height\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('TurkuNLP/bert-base-finnish-cased-v1')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokenized_text = tokenizer.encode(text, add_special_tokens=False)\n",
    "    # Convert token IDs to strings\n",
    "    processed_text = tokenizer.decode(tokenized_text)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file and process sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'computerVision.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "predefined_sentences =  df['texts'].tolist()\n",
    "\n",
    "result_dict = dict(zip(df['texts'], df['img']))\n",
    "\n",
    "# Preprocess each sentence in the predefined list\n",
    "processed_predefined_sentences = []\n",
    "for sentence in predefined_sentences:\n",
    "    input = str(sentence)\n",
    "    if len(input) != 0:\n",
    "        p = preprocess_text(input)\n",
    "        processed_predefined_sentences.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('TurkuNLP/bert-base-finnish-cased-v1')\n",
    "\n",
    "# Encode input and predefined sentences\n",
    "with torch.no_grad():\n",
    "    predefined_ids = tokenizer(processed_predefined_sentences, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "    predefined_embeddings = model(predefined_ids)[0].mean(dim=1)  # Mean pooling over token embeddings for predefined sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031\n",
      "1031\n",
      "1031\n",
      "1031\n"
     ]
    }
   ],
   "source": [
    "# Sanity check on sizes\n",
    "print(len(predefined_ids))\n",
    "print(len(processed_predefined_sentences))\n",
    "print(len(predefined_sentences))\n",
    "print(len(predefined_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"tänään on tilipäivä\"\n",
    "processed_input = preprocess_text(input)\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_ids = tokenizer(processed_input, return_tensors='pt')['input_ids']\n",
    "    input_embeddings = model(input_ids)[0].mean(dim=1)  # Mean pooling over token embeddings for input sentence\n",
    "\n",
    "similarities = cosine_similarity(input_embeddings, predefined_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def displayComic(imagePaths, stripHeight=300):\n",
    "    # Calculate the aspect ratio of each image\n",
    "    aspect_ratios = []\n",
    "    images = []\n",
    "    for path in imagePaths:\n",
    "        img = Image.open(path)\n",
    "        images.append(img)\n",
    "        aspect_ratios.append(img.width / img.height)   \n",
    "    \n",
    "    # Calculate the width of each image based on the strip height\n",
    "    imgWidths = [int(stripHeight * aspect_ratio) for aspect_ratio in aspect_ratios]\n",
    "    \n",
    "    # Create a new blank image for the comic strip\n",
    "    stripWidth = sum(imgWidths)\n",
    "    comicStrip = Image.new('RGB', (stripWidth, stripHeight), color='white')\n",
    "    \n",
    "    # Paste images onto the comic strip\n",
    "    currentX = 0\n",
    "    for img, width in zip(images, imgWidths):\n",
    "        resized = img.resize((width, stripHeight), Image.LANCZOS)\n",
    "        comicStrip.paste(resized, (currentX, 0))\n",
    "        currentX += width\n",
    "    \n",
    "    # Display the comic strip\n",
    "    comicStrip.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frameSet/350-0.jpg', 'frameSet/90-0.jpg', 'frameSet/47-1.jpg']\n"
     ]
    }
   ],
   "source": [
    "numStories = 3\n",
    "# Find the index of the most similar story\n",
    "closestStories = np.argpartition(similarities[0], -numStories)[-numStories:]\n",
    "closestStories = closestStories[np.argsort(similarities[0][closestStories])][::-1]\n",
    "\n",
    "paths = [result_dict[predefined_sentences[i]] for i in closestStories]\n",
    "print(paths)\n",
    "displayComic(paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stripgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
